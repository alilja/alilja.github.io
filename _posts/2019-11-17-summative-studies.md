---
layout: post
title:	Summative Studies
date:   2019-11-17 10:22:34 -0600
categories: work medical-devices recent
---

A large medical device manufacturer needed to replace an aging fleet of clinician-operated tools used to program lifesaving implantable devices. The existing tool was no longer being manufactured, and the company wanted to move away from custom-made hardware towards more flexible, off-the-shelf devices like the iPad. The new programmer needed to do everything the old one had, and be future-proofed to work with new devices in the future with an unknown range of features and improvements.

I was brought onboard after the initial version was completed. My job was to develop, execute, and document the summative testing studies needed to prove to the FDA that the new programmer was a safe and effective replacement. The timeline for the project was highly accelerated, with six studies in 15 months.

Designing a summative study is challenging in both its rigor and its breadth. Features that have been defined as safety-critical need to thoroughly tested in environments that are close to real-world settings as possible, and a poorly designed task can lead to poor data, an FDA rejection, and a development timeline set back by six months or more. 

The first thing I needed to do with each study was understand what features I was using. Without knowing how worked, what they were used for, and what could commonly go wrong, I wouldn't be capable of writing an effective study that actually measured a user's ability to safely and correctly use that feature. I reached out to existing users of a range of skill levels to get a baseline understanding of how it was being used in the field[^field_use] and used that information to begin developing a protocol.

Each task required a unique, carefully-described success criteria. In order to work with as many users as we needed, studies were often carried out by multiple moderators at a time. This meant that the protocols had to be clear and usable by someone without my level of knowledge, and critically, that the moderator could correctly assess whether or not a user had correctly performed the task. This meant identifying what the intended outcome of a task should be and describing what it meant to accomplish that task safely â€” if the user had the right result but did it in an unsafe way, that was a failure of the task.

After each study had concluded, the data needed to be analyzed and summarized into two forms: one in an official document submitted to the FDA, and one for internal usage about any usability or safety issues that needed to be fixed. In order to meet development timelines, this often meant that 30 or 45 participant's data needed to be analyzed, summarized, and have recommendations developed in as little as a week.

In early 2019, the new tool was approved for usage by the FDA. That same year, I worked on formative studies preparing for the next round of validation testing to take place in 2020.

[^field_use]: As we would learn, there could be a large gap between how a feature was used in the field and how it was _supposed_ to be used.